```{r}
# imap kj <Esc>
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Importing the data
```{r echo = FALSE}
library(tidyverse)
library(scales)
library(ggrepel)
library(broom)
library(plotly)

recent_grads <- read_csv("https://raw.githubusercontent.com/fivethirtyeight/data/master/college-majors/recent-grads.csv")

# modified and processed version of the dataset
major_processed <- recent_grads |> 
    arrange(desc(Median)) |> 
    mutate(Major = str_to_title(Major),
           Major = fct_reorder(Major, Median))

# 43:00 Weighting medians and summarise instead of summarise_at
# using just summarise
by_major_category <- major_processed |> 
    dplyr::filter(!is.na(Total)) |> 
    group_by(Major_category) |> 
    # summary_at only for a single method not different methods
    summarise(Men = sum(Men), 
              Women = sum(Women),
              Total = sum(Total),
              # weighting the medain by sample size?
              # medians can also be affected by high variation ones ...
              # high sample size will get more weights
              MedianSalaryWeighted = sum(Median * Sample_size / sum(Sample_size))) |>  
    mutate(ShareWomen = Women / Total) |> 
    arrange(desc(ShareWomen))
```


```{r}
major_processed |> 
    group_by(Major_category) |> 
    summarise(Median = median(Median)) |> 
    mutate(Major_category = fct_reorder(Major_category, Median)) |> 
    ggplot(aes(Major_category, Median)) +
    geom_col() +
    coord_flip()
```

Most common major categories using count

```{r}
major_processed |> 
    count(Major_category, wt = Total, sort = TRUE) |>
    mutate(Major_category = fct_reorder(Major_category, n)) |>
    ggplot(aes(Major_category, n, fill = Major_category)) +
    geom_col() +
    coord_flip() +
    scale_y_continuous(labels = comma_format()) +
    labs(x = "",
         y = "Number of total graduates") +
    theme(legend.position = "none")

major_processed |> 
    group_by(Major_category) |> 
    summarise(n = sum(Total)) |> 
    arrange(desc(n))
```

```{r 34:00}
major_processed |> 
    mutate(Major = fct_reorder(Major, Total)) |>
    arrange(desc(Total)) |> 
    head(20) |> 
    ggplot(aes(Major, Total, fill = Major_category)) +
    geom_col() +
    coord_flip() +
    scale_y_continuous(labels = comma_format()) +
    labs(x = "",
         y = "Total # of graduates") +
    theme(legend.position = "none")
```

36:00 Gender and typical earning
```{r}
major_processed |> 
    arrange(desc(Total)) |> 
    head(20) |> 
    mutate(Major = fct_reorder(Major, Total)) |> 
    gather(Gender, Number, Men, Women) |> 
    select(Major, Gender, Number) |> 
    ggplot(aes(Major, Number, fill = Gender)) +
    geom_col() +
    scale_y_continuous(labels = comma_format()) +
    coord_flip()
```


39:00 Most shifted proportions
```{r}
major_processed |> 
    group_by(Major_category) |> 
    summarise_at(vars(Total, Men, Women), sum, na.rm = TRUE) |> 
    mutate(ShareWomen = Women / Total) |> 
    arrange(desc(ShareWomen))
```


48:00 ShareWomen and salary
```{r}
by_major_category |> 
    arrange(MedianSalaryWeighted) |> 
    mutate(Major_category = fct_reorder(Major_category, MedianSalaryWeighted, .desc = TRUE)) |> 
    arrange(Major_category) |> 
    ggplot(aes(Major_category, MedianSalaryWeighted, fill = ShareWomen)) +
    geom_col() +
    scale_y_continuous(labels = dollar_format()) +
    coord_flip() +
    labs(x = "",
         y = "",
         title = "Hello World!")

# Engeneering and CS are outliers in two dimentions
# in higher salara and more men in Total!!!
by_major_category |> 
    ggplot(aes(ShareWomen, MedianSalaryWeighted)) +
    geom_point() +
    geom_smooth(method = "lm") +
    geom_text_repel(aes(label = Major_category), force = .2) +
    expand_limits(y = 1000)

major_processed |> 
    ggplot(aes(ShareWomen, Median)) +
    geom_point(aes(colour = Major_category)) +
    geom_smooth(method = "lm", aes(colour = Major_category)) +
    expand_limits(y = 10000)
```


53:00 First statistics

```{r}
mj_lm <- major_processed |> 
    select(Major, Total, ShareWomen, Sample_size, Median)

lm(Median ~ ShareWomen, data = mj_lm, weights = Sample_size)

major_processed |> 
  select(Major, Total, ShareWomen, Sample_size, Median) %>% # you need this pipe here!
  lm(Median ~ ShareWomen, data = ., weights = Sample_size) |>
    summary() # every percent mor men, there will be an increase in salary by 236 dollars!
```


56:00 Nested data frames ect 

```{r}

nested_major_processed <- major_processed |> 
    select(Major, Major_category, Total, ShareWomen, Sample_size, Median) |> 
    # counts the majors in a category (this is why counts are repeate in n column)
    # this is similar to table but adds a column, pretty cool
    add_count(Major_category) |> 
    filter(n >= 10) |> 
    nest(-Major_category) %>%
    mutate(model = map(data, ~ lm(Median ~ ShareWomen, data = ., weights = Sample_size)),
           # amazing -> providing model to map inside mutate ... nice
           tiedied = map(model, tidy)) |> 
    unnest(tiedied) |> 
    filter(term == "ShareWomen") |> 
    arrange(estimate) |> 
    # p values will be not significant after bonferroni correcection (multiplication by n groups)
    # false descovery rate control is better
    mutate(fdr = p.adjust(p.value, method = "fdr"))
```

1:06 cool boxplot for highest median salary

```{r}
major_processed |> 
    mutate(Major_category = fct_reorder(Major_category, Median)) |> 
    ggplot(aes(Major_category, Median, fill = Major_category)) +
    geom_boxplot() +
    theme(legend.position = "none") +
    scale_y_continuous(labels = dollar_format()) +
    expand_limits(y = 0) +
    coord_flip()
```
1:06 What are the highest and lowest earning majors 

```{r}
# highest earing majors
major_processed |> 
    filter(Sample_size >= 100) %>%
    head(20) %>%
    ggplot(aes(Major, Median, color = Major_category)) +
    geom_point() +
    geom_errorbar(aes(ymin = P25th, ymax = P75th)) +
    expand_limits(y = 0) +
    scale_y_continuous(labels = dollar_format()) +
    coord_flip() +
    labs(title = "What are the highest-earning majors",
         subtitle = "Top 20 earning majors with corresponding percentiles")

# lowest
major_processed |> 
    filter(Sample_size >= 100) %>%
    tail(20) %>%
    ggplot(aes(Major, Median, color = Major_category)) +
    geom_point() +
    geom_errorbar(aes(ymin = P25th, ymax = P75th)) +
    expand_limits(y = 0) +
    scale_y_continuous(labels = dollar_format()) +
    coord_flip() +
    labs(title = "What are the highest-earning majors",
         subtitle = "Top 20 earning majors with corresponding percentiles")

```
1:08 Why choosing Sample size 100, low sample size has higher variation

```{r}
major_processed |> 
    ggplot(aes(Sample_size, Median)) +
    geom_point() +
    geom_text(aes(label = Major), check_overlap = TRUE, vjust = 1, hjust = 1) +
    # expand_limits(y = 0)
    scale_x_log10()
```

1:09 Linear model and scatter plot using lump! Plotly graph

```{r}
plotly_g <- major_processed |>
    mutate(Major_category = fct_lump(Major_category, 6)) |> 
    ggplot(aes(ShareWomen, Median, color = Major_category, size = Sample_size)) +
    geom_point() +
    geom_smooth(aes(group = 1), method = "lm") +
    expand_limits(x = 0)

ggplotly(plotly_g)
    
```